{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from metric import amex_metric\n",
    "from train import CFG, seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"gs://leoraggio-kaggle/amex-default-prediction/data/processed/train_data.parquet\")\n",
    "df_test = pd.read_parquet(\"gs://leoraggio-kaggle/amex-default-prediction/data/processed/test_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(train, test):\n",
    "    # Label encode categorical features\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        test[cat_col] = encoder.transform(test[cat_col])\n",
    "    # Round last float features to 2 decimal place\n",
    "    num_cols = list(\n",
    "        train.dtypes[(train.dtypes == \"float32\") | (train.dtypes == \"float64\")].index\n",
    "    )\n",
    "    num_cols = [col for col in num_cols if \"last\" in col]\n",
    "    for col in num_cols:\n",
    "        train[col + \"_round2\"] = train[col].round(2)\n",
    "        test[col + \"_round2\"] = test[col].round(2)\n",
    "    # Get the difference between last and mean\n",
    "    num_cols = [col for col in train.columns if \"last\" in col]\n",
    "    num_cols = [col[:-5] for col in num_cols if \"round\" not in col]\n",
    "    for col in num_cols:\n",
    "        try:\n",
    "            train[f\"{col}_last_mean_diff\"] = train[f\"{col}_last\"] - train[f\"{col}_mean\"]\n",
    "            test[f\"{col}_last_mean_diff\"] = test[f\"{col}_last\"] - test[f\"{col}_mean\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = process_data(df_train, df_test)\n",
    "features = [col for col in df_train.columns if col not in [\"customer_ID\", CFG.target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.fillna(-128, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "def rfc_cv(\n",
    "    n_estimators,\n",
    "    min_samples_split,\n",
    "    min_samples_leaf,\n",
    "    max_features,\n",
    "    data,\n",
    "    targets):\n",
    "    estimator = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=CFG.seed,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(\" \")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"=== n_estimators: {n_estimators}\")\n",
    "    print(f\"=== min_samples_split: {min_samples_split}\")\n",
    "    print(f\"=== min_samples_leaf: {min_samples_leaf}\")\n",
    "    print(f\"=== max_features: {max_features}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    oof_predictions = np.zeros(len(data))\n",
    "    kfold = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(data, targets)):\n",
    "        print(\" \")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Training fold {fold} with {len(features)} features...\")\n",
    "        x_train, x_val = data.iloc[train_idx], data.iloc[val_idx]\n",
    "        y_train, y_val = targets.iloc[train_idx], targets.iloc[val_idx]\n",
    "\n",
    "        # Train model\n",
    "        model = estimator.fit(x_train, y_train)\n",
    "        joblib.dump(\n",
    "            model,\n",
    "            f\"../Models/rf_fold{fold}_seed{CFG.seed}.joblib\",\n",
    "        )\n",
    "        \n",
    "        # Train score\n",
    "        train_pred = model.predict_proba(x_train)\n",
    "        train_pred = np.array([p[1] for p in train_pred])\n",
    "        train_score = amex_metric(y_train, train_pred)\n",
    "        print(f\"Our fold {fold} train score is {train_score}\")\n",
    "\n",
    "        # Predict validation\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = np.array([p[1] for p in val_pred])\n",
    "        oof_predictions[val_idx] = val_pred\n",
    "        val_score = amex_metric(y_val, val_pred)\n",
    "        print(f\"Our fold {fold} CV score is {val_score}\")\n",
    "        del x_train, x_val, y_train, y_val\n",
    "        gc.collect()\n",
    "    \n",
    "    score = amex_metric(targets, oof_predictions)\n",
    "    print(f\"Final Score: {score}\")\n",
    "    return score\n",
    "\n",
    "\n",
    "def optimize_rfc(data, targets):\n",
    "    \"\"\"Apply Bayesian Optimization to Random Forest parameters.\"\"\"\n",
    "\n",
    "    def rfc_crossval(n_estimators, min_samples_split, min_samples_leaf, max_features):\n",
    "        \"\"\"Wrapper of RandomForest cross validation.\n",
    "        Notice how we ensure n_estimators and min_samples_split are casted\n",
    "        to integer before we pass them along. Moreover, to avoid max_features\n",
    "        taking values outside the (0, 1) range, we also ensure it is capped\n",
    "        accordingly.\n",
    "        \"\"\"\n",
    "        return rfc_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            min_samples_leaf=int(min_samples_leaf),\n",
    "            max_features=max(min(max_features, 0.999), 1e-3),\n",
    "            data=data,\n",
    "            targets=targets,\n",
    "        )\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=rfc_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\": (100, 250),\n",
    "            \"min_samples_split\": (2, 25),\n",
    "            \"min_samples_leaf\": (1, 25),\n",
    "            \"max_features\": (0.1, 0.999),\n",
    "        },\n",
    "        random_state=CFG.seed,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=10)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_fe... | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 107\n",
      "=== min_samples_split: 4\n",
      "=== min_samples_leaf: 12\n",
      "=== max_features: 0.10841339381318048\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9289963383501529\n",
      "Our fold 0 CV score is 0.7447628522111074\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9276518848027778\n",
      "Our fold 1 CV score is 0.7616865556956924\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9291917667666066\n",
      "Our fold 2 CV score is 0.7705922401532861\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.9302032295839657\n",
      "Our fold 3 CV score is 0.7482828360910547\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9293590303761936\n",
      "Our fold 4 CV score is 0.7485911884399157\n",
      "Final Score: 0.7560543510823804\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7561  \u001b[0m | \u001b[0m 0.1084  \u001b[0m | \u001b[0m 12.98   \u001b[0m | \u001b[0m 4.608   \u001b[0m | \u001b[0m 107.5   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 197\n",
      "=== min_samples_split: 22\n",
      "=== min_samples_leaf: 12\n",
      "=== max_features: 0.7161814272245395\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9407046555275589\n",
      "Our fold 0 CV score is 0.7347364402081387\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9394878919118277\n",
      "Our fold 1 CV score is 0.7602605356752712\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9394117194640208\n",
      "Our fold 2 CV score is 0.7629544955865233\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.942236292925973\n",
      "Our fold 3 CV score is 0.7483411289786958\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9412203640816748\n",
      "Our fold 4 CV score is 0.7463168906076143\n",
      "Final Score: 0.7507209800961604\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7507  \u001b[0m | \u001b[0m 0.7162  \u001b[0m | \u001b[0m 12.69   \u001b[0m | \u001b[0m 22.65   \u001b[0m | \u001b[0m 197.1   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 224\n",
      "=== min_samples_split: 21\n",
      "=== min_samples_leaf: 18\n",
      "=== max_features: 0.906369847389106\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9074982118482564\n",
      "Our fold 0 CV score is 0.7326892430260854\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9042715919594551\n",
      "Our fold 1 CV score is 0.7537931941847524\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9027898446645497\n",
      "Our fold 2 CV score is 0.7586962673791029\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.9055619179545598\n",
      "Our fold 3 CV score is 0.7540055850627406\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9055262754301847\n",
      "Our fold 4 CV score is 0.7462565684238562\n",
      "Final Score: 0.7484762109981826\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7485  \u001b[0m | \u001b[0m 0.9064  \u001b[0m | \u001b[0m 18.31   \u001b[0m | \u001b[0m 21.12   \u001b[0m | \u001b[0m 224.1   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 174\n",
      "=== min_samples_split: 10\n",
      "=== min_samples_leaf: 23\n",
      "=== max_features: 0.8493880460682682\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.8843314639025068\n",
      "Our fold 0 CV score is 0.7343036548204334\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.8815617987508959\n",
      "Our fold 1 CV score is 0.7572323209993583\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.8830320234063387\n",
      "Our fold 2 CV score is 0.7605256950254918\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.8845022254983179\n",
      "Our fold 3 CV score is 0.7533079708958108\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.8864870743369303\n",
      "Our fold 4 CV score is 0.7461867208039189\n",
      "Final Score: 0.750200695446195\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7502  \u001b[0m | \u001b[0m 0.8494  \u001b[0m | \u001b[0m 23.97   \u001b[0m | \u001b[0m 10.47   \u001b[0m | \u001b[0m 174.2   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 114\n",
      "=== min_samples_split: 24\n",
      "=== min_samples_leaf: 15\n",
      "=== max_features: 0.40521901765415425\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9170046765721005\n",
      "Our fold 0 CV score is 0.7392365963465862\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9174836629810258\n",
      "Our fold 1 CV score is 0.7612422675374967\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9162078367657396\n",
      "Our fold 2 CV score is 0.7590507003464371\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.9202580910717217\n",
      "Our fold 3 CV score is 0.7534529207111043\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9190747776956465\n",
      "Our fold 4 CV score is 0.7448960412119754\n",
      "Final Score: 0.7524068411824112\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7524  \u001b[0m | \u001b[0m 0.4052  \u001b[0m | \u001b[0m 15.87   \u001b[0m | \u001b[0m 24.48   \u001b[0m | \u001b[0m 114.5   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 108\n",
      "=== min_samples_split: 4\n",
      "=== min_samples_leaf: 14\n",
      "=== max_features: 0.7987066854836291\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9258103058811863\n",
      "Our fold 0 CV score is 0.7351813908901323\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9237625550987273\n",
      "Our fold 1 CV score is 0.7549583865500087\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9239884090159753\n",
      "Our fold 2 CV score is 0.7567952154583808\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.928868284080745\n",
      "Our fold 3 CV score is 0.7539953770403403\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9274779602153611\n",
      "Our fold 4 CV score is 0.7496749936501259\n",
      "Final Score: 0.7500977953745629\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7501  \u001b[0m | \u001b[0m 0.7987  \u001b[0m | \u001b[0m 14.56   \u001b[0m | \u001b[0m 4.138   \u001b[0m | \u001b[0m 108.1   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 108\n",
      "=== min_samples_split: 9\n",
      "=== min_samples_leaf: 21\n",
      "=== max_features: 0.9816367355801462\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.8924219524295435\n",
      "Our fold 0 CV score is 0.7282672791298247\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.8900427666720458\n",
      "Our fold 1 CV score is 0.754917976467617\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.8898735490657477\n",
      "Our fold 2 CV score is 0.7577197048608633\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.8920672756061157\n",
      "Our fold 3 CV score is 0.7494962604579205\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.8936454975533408\n",
      "Our fold 4 CV score is 0.7476241505026076\n",
      "Final Score: 0.7489416935127378\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 0.9816  \u001b[0m | \u001b[0m 21.1    \u001b[0m | \u001b[0m 9.409   \u001b[0m | \u001b[0m 108.0   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 123\n",
      "=== min_samples_split: 23\n",
      "=== min_samples_leaf: 4\n",
      "=== max_features: 0.6134601294192089\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9764776324669294\n",
      "Our fold 0 CV score is 0.7298995719031915\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.976155396152278\n",
      "Our fold 1 CV score is 0.7469895764496453\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9764325365656499\n",
      "Our fold 2 CV score is 0.7495140986800579\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.9787593274366659\n",
      "Our fold 3 CV score is 0.7393477275786267\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9773698967706721\n",
      "Our fold 4 CV score is 0.7378752812697658\n",
      "Final Score: 0.7401431281873949\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7401  \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 4.181   \u001b[0m | \u001b[0m 23.66   \u001b[0m | \u001b[0m 123.6   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 108\n",
      "=== min_samples_split: 5\n",
      "=== min_samples_leaf: 13\n",
      "=== max_features: 0.3385739841067699\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9307027928818424\n",
      "Our fold 0 CV score is 0.7400765992157391\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9281020025112936\n",
      "Our fold 1 CV score is 0.7650000378340636\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.929317595125799\n",
      "Our fold 2 CV score is 0.7684801110012228\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.9301331455293053\n",
      "Our fold 3 CV score is 0.7513360615826108\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.930357997062828\n",
      "Our fold 4 CV score is 0.7475639541038482\n",
      "Final Score: 0.7535195512888038\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7535  \u001b[0m | \u001b[0m 0.3386  \u001b[0m | \u001b[0m 13.13   \u001b[0m | \u001b[0m 5.153   \u001b[0m | \u001b[0m 108.5   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 106\n",
      "=== min_samples_split: 6\n",
      "=== min_samples_leaf: 11\n",
      "=== max_features: 0.6576913718561488\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9455436986311008\n",
      "Our fold 0 CV score is 0.7311163666301717\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9441307583726645\n",
      "Our fold 1 CV score is 0.7595588648346268\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9479093608378486\n",
      "Our fold 2 CV score is 0.7584293009236089\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.9489255083193695\n",
      "Our fold 3 CV score is 0.7459421613339332\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9486805240918843\n",
      "Our fold 4 CV score is 0.7460085464643292\n",
      "Final Score: 0.7488211596233023\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7488  \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 11.86   \u001b[0m | \u001b[0m 6.293   \u001b[0m | \u001b[0m 106.6   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 107\n",
      "=== min_samples_split: 3\n",
      "=== min_samples_leaf: 12\n",
      "=== max_features: 0.6023402439130968\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9372218289368943\n",
      "Our fold 0 CV score is 0.7313282993343663\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9370064040571496\n",
      "Our fold 1 CV score is 0.76267903874857\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.939317812611248\n",
      "Our fold 2 CV score is 0.7612403325613952\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.940514703835651\n",
      "Our fold 3 CV score is 0.7469570944332875\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9390764297260993\n",
      "Our fold 4 CV score is 0.7475080863298649\n",
      "Final Score: 0.7516205878474878\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7516  \u001b[0m | \u001b[0m 0.6023  \u001b[0m | \u001b[0m 12.42   \u001b[0m | \u001b[0m 3.002   \u001b[0m | \u001b[0m 107.1   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 107\n",
      "=== min_samples_split: 5\n",
      "=== min_samples_leaf: 14\n",
      "=== max_features: 0.6311414383369419\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9245907722066149\n",
      "Our fold 0 CV score is 0.7342502015585333\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9245884821852627\n",
      "Our fold 1 CV score is 0.7566953186882057\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9239133895243804\n",
      "Our fold 2 CV score is 0.7587274567841954\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.9274338449326947\n",
      "Our fold 3 CV score is 0.7518371310724189\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9267417694312068\n",
      "Our fold 4 CV score is 0.7457881047903201\n",
      "Final Score: 0.7492562362611251\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7493  \u001b[0m | \u001b[0m 0.6311  \u001b[0m | \u001b[0m 14.19   \u001b[0m | \u001b[0m 5.191   \u001b[0m | \u001b[0m 107.0   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 108\n",
      "=== min_samples_split: 3\n",
      "=== min_samples_leaf: 13\n",
      "=== max_features: 0.9201413503672758\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9347061287002529\n",
      "Our fold 0 CV score is 0.7321260863703205\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9301719041685189\n",
      "Our fold 1 CV score is 0.7554682548927298\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9320577739716238\n",
      "Our fold 2 CV score is 0.7582723018745618\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.9348074143559257\n",
      "Our fold 3 CV score is 0.749175167650548\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9345165870879644\n",
      "Our fold 4 CV score is 0.747747022075011\n",
      "Final Score: 0.747944120203162\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7479  \u001b[0m | \u001b[0m 0.9201  \u001b[0m | \u001b[0m 13.13   \u001b[0m | \u001b[0m 3.58    \u001b[0m | \u001b[0m 108.6   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 108\n",
      "=== min_samples_split: 6\n",
      "=== min_samples_leaf: 12\n",
      "=== max_features: 0.3393053959266459\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9368634340084172\n",
      "Our fold 0 CV score is 0.7398892940825357\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.933918646476884\n",
      "Our fold 1 CV score is 0.759144817308681\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9356211051214114\n",
      "Our fold 2 CV score is 0.7622916754247212\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.938120108605196\n",
      "Our fold 3 CV score is 0.7502668073793337\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9378640119699095\n",
      "Our fold 4 CV score is 0.7434560192617661\n",
      "Final Score: 0.7510009099732221\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.751   \u001b[0m | \u001b[0m 0.3393  \u001b[0m | \u001b[0m 12.29   \u001b[0m | \u001b[0m 6.36    \u001b[0m | \u001b[0m 108.5   \u001b[0m |\n",
      " \n",
      "==================================================\n",
      "=== n_estimators: 106\n",
      "=== min_samples_split: 5\n",
      "=== min_samples_leaf: 12\n",
      "=== max_features: 0.6596227353288742\n",
      "==================================================\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "Our fold 0 train score is 0.9385432916217118\n",
      "Our fold 0 CV score is 0.735108642126057\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "Our fold 1 train score is 0.9366679327547451\n",
      "Our fold 1 CV score is 0.7649199643775113\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "Our fold 2 train score is 0.9374895021527372\n",
      "Our fold 2 CV score is 0.755184146641183\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "Our fold 3 train score is 0.9396549915718113\n",
      "Our fold 3 CV score is 0.7492445223874601\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "Our fold 4 train score is 0.9408452042303233\n",
      "Our fold 4 CV score is 0.7489554126655477\n",
      "Final Score: 0.750481221366712\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7505  \u001b[0m | \u001b[0m 0.6596  \u001b[0m | \u001b[0m 12.89   \u001b[0m | \u001b[0m 5.037   \u001b[0m | \u001b[0m 106.4   \u001b[0m |\n",
      "=========================================================================\n",
      "Final result: {'target': 0.7560543510823804, 'params': {'max_features': 0.10841339381318048, 'min_samples_leaf': 12.977387460447712, 'min_samples_split': 4.607824868501209, 'n_estimators': 107.49610272664457}}\n"
     ]
    }
   ],
   "source": [
    "train_sample = df_train.groupby(CFG.target).sample(frac=0.1)\n",
    "x_train = train_sample[features]\n",
    "y_train = train_sample[CFG.target]\n",
    "\n",
    "optimize_rfc(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23419/3180208804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_sample' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
